{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizagem Supervisionada\n",
    "## Projeto 2: Construindo um Sistema de Intervenção para Estudantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem-vindo ao segundo projeto do Nanodegree de Machine Learning! Neste Notebook, alguns templates de código já foram fornecidos, e será o seu trabalho implementar funcionalidades necessárias para completar este projeto com êxito. Seções que começam com **'Implementação'** no cabeçalho indicam que o bloco de código que se segue precisará de funcionalidades adicionais que você deve fornecer. Instruções serão providenciadas para cada seção e as especificações para cada implementação estarão marcadas no bloco de código com o comando `'TODO'`. Tenha certeza de ler atentamente todas as instruções!\n",
    "\n",
    "Além do código implementado, haverá questões relacionadas ao projeto e à implementação que você deve responder. Cada seção em que você tem que responder uma questão será antecedida de um cabeçalho **'Questão X'**. Leia atentamente cada questão e escreva respostas completas nas caixas de texto subsequentes que começam com **'Resposta: '**. O projeto enviado será avaliado baseado nas respostas para cada questão e a implementação que você forneceu.  \n",
    "\n",
    ">**Nota:** Células de código e Markdown podem ser executadas utilizando o atalho de teclado **Shift + Enter**. Além disso, as células Markdown podem ser editadas, um clique duplo na célula entra no modo de edição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Classificação versus Regressão\n",
    "*Seu objetivo neste projeto é identificar estudantes que possam precisar de intervenção antecipada antes de serem reprovados. Que tipo de problema de aprendizagem supervisionada é esse: classificação ou regressão? Por quê?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **Eu diria classificação. Não estamos tentando prever, exatamente, o quão bem o aluno irá, mas simplesmente classificá-lo como aprovado ou reprovado. Penso que é geralmente beneficial atacar o problema com as ferramentas mais simples que temos, do que tentar algo maior que pode deixar tudo mais complexo. Dando uma olhadinha mais abaixo vi que a label (o y da função) é uma coluna chamada `'passed'`, que indica um valor booleano. Assim, fica bem mais claro que com os dados que temos, estamos tentando encontrar um modelo que retorne 0 ou 1 para essa coluna, com base nos outros fatores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observando os Dados\n",
    "Execute a célula de código abaixo para carregar as bibliotecas de Python necessárias e os dados sobre os estudantes. Note que a última coluna desse conjunto de dados, `'passed'`, será nosso rótulo alvo (se o aluno foi ou não aprovado). As outras colunas são atributos sobre cada aluno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados dos estudantes foram lidos com êxito!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Ler os dados dos estudantes\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Os dados dos estudantes foram lidos com êxito!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Observando os Dados\n",
    "Vamos começar observando o conjunto de dados para determinar quantos são os estudantes sobre os quais temos informações e entender a taxa de graduação entre esses estudantes. Na célula de código abaixo, você vai precisar calcular o seguinte:\n",
    "- O número total de estudantes, `n_students`.\n",
    "- O número total de atributos para cada estudante, `n_features`.\n",
    "- O número de estudantes aprovados, `n_passed`.\n",
    "- O número de estudantes reprovados, `n_failed`.\n",
    "- A taxa de graduação da classe, `grad_rate`, em porcentagem (%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de estudantes: 395.0\n",
      "Número de atributos: 30\n",
      "Número de estudantes aprovados: 265\n",
      "Número de estudantes reprovados: 130\n",
      "Taxa de graduação: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calcule o número de estudante\n",
    "n_students = float(student_data.shape[0])\n",
    "\n",
    "# TODO: Calcule o número de atributos\n",
    "n_features = student_data.shape[1] - 1 # Exceto o outcome 'y'\n",
    "\n",
    "# TODO: Calcule o número de alunos aprovados\n",
    "n_passed = student_data.loc[student_data[\"passed\"] == \"yes\"].shape[0]\n",
    "\n",
    "# TODO: Calcule o número de alunos reprovados\n",
    "n_failed = student_data.loc[student_data[\"passed\"] == \"no\"].shape[0]\n",
    "\n",
    "# TODO: Calcule a taxa de graduação\n",
    "grad_rate = np.divide(n_passed, n_students) * 100\n",
    "\n",
    "# Imprima os resultados\n",
    "print \"Número total de estudantes: {}\".format(n_students)\n",
    "print \"Número de atributos: {}\".format(n_features)\n",
    "print \"Número de estudantes aprovados: {}\".format(n_passed)\n",
    "print \"Número de estudantes reprovados: {}\".format(n_failed)\n",
    "print \"Taxa de graduação: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os Dados\n",
    "Nesta seção, vamos preparara os dados para modelagem, treinamento e teste.\n",
    "\n",
    "### Identificar atributos e variáveis-alvo\n",
    "É comum que os dados que você obteve contenham atributos não numéricos. Isso pode ser um problema, dado que a maioria dos algoritmos de machine learning esperam dados númericos para operar cálculos.\n",
    "\n",
    "Execute a célula de código abaixo para separar os dados dos estudantes em atributos e variáveis-alvo e verificar se algum desses atributos é não numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de atributos:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Coluna-alvo: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extraia as colunas dos atributo\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# Extraia a coluna-alvo 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Mostre a lista de colunas\n",
    "print \"Colunas de atributos:\\n{}\".format(feature_cols)\n",
    "print \"\\nColuna-alvo: {}\".format(target_col)\n",
    "\n",
    "# Separe os dados em atributos e variáveis-alvo (X_all e y_all, respectivamente)\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# Mostre os atributos imprimindo as cinco primeiras linhas\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processar Colunas de Atributo\n",
    "\n",
    "Como você pode ver, há muitas colunas não numéricas que precisam ser convertidas! Muitas delas são simplesmente `yes`/`no`, por exemplo, a coluna `internet`. É razoável converter essas variáveis em valores (binários) `1`/`0`.\n",
    "\n",
    "Outras colunas, como `Mjob` e `Fjob`, têm mais do que dois valores e são conhecidas como variáveis categóricas. A maneira recomendada de lidar com esse tipo de coluna é criar uma quantidade de colunas proporcional aos possíveis valores (por exemplo, `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc), e assinalar `1` para um deles e `0` para todos os outros.\n",
    "\n",
    "Essas colunas geradas são por vezes chamadas de _variáveis postiças_ (_dummy variables_), e nós iremos utilizar a função [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para fazer essa conversão. Execute a célula de código abaixo para executar a rotina de pré-processamento discutida nesta seção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Pré-processa os dados dos estudantes e converte as variáveis binárias não numéricas em\n",
    "        variáveis binárias (0/1). Converte variáveis categóricas em variáveis postiças. '''\n",
    "    \n",
    "    # Inicialize nova saída DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Observe os dados em cada coluna de atributos \n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # Se o tipo de dado for não numérico, substitua todos os valores yes/no por 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # Se o tipo de dado for categórico, converta-o para uma variável dummy\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Reúna as colunas revisadas\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Divisão dos Dados de Treinamento e Teste\n",
    "Até agora, nós convertemos todos os atributos _categóricos_ em valores numéricos. Para o próximo passo, vamos dividir os dados (tanto atributos como os rótulos correspondentes) em conjuntos de treinamento e teste. Na célula de código abaixo, você irá precisar implementar o seguinte:\n",
    "- Embaralhe aleatoriamente os dados (`X_all`, `y_all`) em subconjuntos de treinamento e teste.\n",
    "  - Utilizar 300 pontos de treinamento (aproxidamente 75%) e 95 pontos de teste (aproximadamente 25%).\n",
    "  - Estabelecer um `random_state` para as funções que você utiliza, se a opção existir.\n",
    "  - Armazene os resultados em `X_train`, `X_test`, `y_train` e `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de treinamento tem 300 amostras.\n",
      "O conjunto de teste tem 95 amostras.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe qualquer funcionalidade adicional de que você possa precisar aqui\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Emabaralhe e distribua o conjunto de dados de acordo com o número de pontos de treinamento e teste abaixo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=.24, random_state=42)\n",
    "\n",
    "# Mostre o resultado da distribuição\n",
    "print \"O conjunto de treinamento tem {} amostras.\".format(X_train.shape[0])\n",
    "print \"O conjunto de teste tem {} amostras.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando Modelos\n",
    "Nesta seção, você irá escolher 3 modelos de aprendizagem supervisionada que sejam apropriados para esse problema e que estejam disponíveis no `scikit-learn`. Primeiro você irá discutir o raciocínio por trás da escolha desses três modelos considerando suas vantagens e desvantagens e o que você sabe sobre os dados. Depois você irá ajustar o modelo a diferentes tamanhos de conjuntos de treinamento (com 100, 200 e 300 pontos) e medir a pontuação F<sub>1</sub>. Você vai precisar preencher três tabelas (uma para cada modelo) que mostrem o tamanho do conjunto de treinamento, o tempo de treinamento, o tempo de previsão e a pontuação F<sub>1</sub> no conjunto de treinamento.\n",
    "\n",
    "**Os seguintes modelos de aprendizagem supervisionada estão atualmente disponíveis no **[`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)** para você escolher:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Árvores de Decisão\n",
    "- Métodos de agregação (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Método do gradiente estocástico (SGDC)\n",
    "- Máquinas de vetores de suporte (SVM)\n",
    "- Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação dos Modelos\n",
    "*Liste três modelos de aprendizagem supervisionada que são apropriadas para esse problema. Para cada modelo escolhido:*\n",
    "- Descreva uma aplicação em mundo real na indústria em que o modelo pode ser aplicado. *(Talvez você precise fazer um pouco de pesquisa para responder essa questão – dê as devidas referências!)* \n",
    "- Quais são as vantagens do modelo; quando ele tem desempenho melhor? \n",
    "- Quais são as desvantagens do modelo, quando ele tem desempenho pior?\n",
    "- O que faz desse modelo um bom candidato para o problema, considerando o que você sabe sobre os dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "* Gradient Boosting: \n",
    "    * Eu tinha impressão que essa seria uma boa opção e fui à procura ver isso se confirmava. Fiquei bastante surpreso ao achar que Boosting parece realmente ser bastante usado por aí. Em um dos sites¹ que encontrei vi que Gradient Boosting é bastante usado nas competições do Kaggle (que espero participar no futuro) por ser um modelo bem robusto. Vi que posso correr o risco de não ter muito sucesso se o Dataset for pequeno, mas vai ser uma experimentação interessante.\n",
    "    * Quanto mais dados melhor para esse modelo. Se houverem dados suficientes ele poderá encontrar quais são as 'perguntas' mais difíceis sobre o Dataset e, com a força de inúmeros weak-learners, formar um modelo bastante robusto e rápido.\n",
    "    * Over-fitting parece ser o maior desafio se os weak-learners não tiverem dados suficientes para gerarem suas hipóteses.\n",
    "    * Não tenho exatamente uma noção de como Boosting vai se comportar nesse Dataset. Em outro curso treinei uma rede neural bem simples com cerca de 10 mil registros, com acurácia de 84% se me lembro corretamente. No nosso caso são menos de 400 registros o que pode dar muito viés para o modelo, mas acho que vale a pena ver para melhorar minha noção sobre o que são muitos/poucos dados. Se eu tivesse que coletar esses dados na mão, 300 me pareceria um bocado de coisa =D.\n",
    "* Decision Tree:\n",
    "    * Encontrar aplicações no mundo real² com Decision Trees foi bem fácil e a resposta é praticamente tudo. Agricultura, Medicina, Física, Processamento de Texto, etc. Acho que dado que o modelo é bastante simples de entender conceitualmente, isso acaba incentivando mais áreas do conhecimento a usá-lo como recurso.\n",
    "    * Decision Trees são bastante claras em seu propósito. Haverão condições que seguirão ramos até haver uma resposta (no nosso caso, se o aluno foi aprovado ou não). Assim é uma caixa-branca, onde podemos entender o que está acontecendo e ficará mais claro quais o fatores que resultam na aprovação ou não dos alunos (em parte eu imagino, pois ainda assim são muitos fatores que levam a isso).\n",
    "    * As desvantagens ficam sendo o alto viés e a complexidade. O Dataset que estamos usando tem inúmeras colunas e corremos o risco que algumas variáveis categóricas gerarem uma decisão que mudará completamente a resposta do modelo, podendo ser um tanto imprevisível. Isso ficará mais visível nas métricas de desempenho.\n",
    "    * Quando estava considerando SVM, vi que um problema seria chegar para o diretor da escola com as classificações multidimensionais de um modelo SVM e explicar pra ele porque isso fazia sentido, afinal nem para mim faria muito sentido. Pelo contrário, DTs tomam decisões mais lógicas para o cérebro humano e as visualizações que eu poderia apresentar ao diretores fariam bem mais sentido. Além de que colocar DT e NB lado a lado será interessante. Vamos poder ver como o *over-fitting* vai afetar a DT e partimos para NB que tenderá a ter menos problemas de alto viés.\n",
    "* Naive Bayes: \n",
    "    * Colocar NB na lista não foi tão óbvio pra mim de início mas no último item vou discorrer porque decidi incluir. Quando pesquisei sobre aplicações me pareceu que ele teria bons resultados, pois como visto nas respostas³ da referência, detecção de spam é um tipo de classificação com algumas semelhanças ao problema em questão.\n",
    "    * NB pode se virar com uma quantidade não muito grande de dados e, por ser probabilístico, a aproximação de suas respostas podem ter bom uso na prática. Mais uma vantagem é o fato de ele não ser tão sensitivo a dados não relevantes, como foi visto no curso.\n",
    "    * A desvantagem que mais me deixou em dúvida sobre colocar ou não NB é que ele não considera a relação entre os fatores. Como visto bem no início do curso, uma criança em um evento político não necessariamente planeja matar o presidente só por estar nervosa, e um modelo probabilístico como NB pode assumir que sim.\n",
    "    * Minha outra consideração estava sendo SVM qu,e quando pesquisei por aplicações reais, vi que é muito mais utilizado em processos não tão intuitívos. Na referência (4), vi que SVMs são usadas em Detecção Facial, Classificação de Imagens, Detecção de texto escrito, etc. Coisas que não deixam claro qual foi a tomada de decisão para a classificação escolhida pelo modelo. Por outro lado NB é mais transparente em seu funcionamento e não corre um risco tão alto de alto viés como SVM. \n",
    "\n",
    "Refências Pesquisadas:\n",
    "1. https://www.analyticsvidhya.com/blog/2015/05/boosting-algorithms-simplified/\n",
    "2. http://legacydirs.umiacs.umd.edu/~salzberg/docs/murthy_thesis/survey/node32.html\n",
    "3. https://www.quora.com/In-what-real-world-applications-is-Naive-Bayes-classifier-used\n",
    "4. https://data-flair.training/blogs/applications-of-svm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração\n",
    "Execute a célula de código abaixo para inicializar três funções de ajuda que você pode utilizar para treinar e testar os três modelos de aprendizagem supervisionada que você escolheu acima. As funções são as seguintes:\n",
    "- `train_classifier` - recebe como parâmetro um classificador e dados de treinamento e ajusta o classificador aos dados.\n",
    "- `predict_labels` - recebe como parâmetro um classificador ajustado, atributos e rótulo alvo e faz estimativas utilizando a pontuação do F<sub>1</sub>.\n",
    "- `train_predict` - recebe como entrada um classificador, e dados de treinamento e teste, e executa `train_clasifier` e `predict_labels`.\n",
    " - Essa função vai dar a pontuação F<sub>1</sub> tanto para os dados de treinamento como para os de teste, separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Ajusta um classificador para os dados de treinamento. '''\n",
    "    \n",
    "    # Inicia o relógio, treina o classificador e, então, para o relógio\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados\n",
    "    print \"O modelo foi treinado em {:.4f} segundos\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Faz uma estimativa utilizando um classificador ajustado baseado na pontuação F1. '''\n",
    "    \n",
    "    # Inicia o relógio, faz estimativas e, então, o relógio para\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados de retorno\n",
    "    print \"As previsões foram feitas em {:.4f} segundos.\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Treina e faz estimativas utilizando um classificador baseado na pontuação do F1. '''\n",
    "    \n",
    "    # Indica o tamanho do classificador e do conjunto de treinamento\n",
    "    print \"Treinando um {} com {} pontos de treinamento. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Treina o classificador\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Imprime os resultados das estimativas de ambos treinamento e teste\n",
    "    print \"Pontuação F1 para o conjunto de treino: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"Pontuação F1 para o conjunto de teste: {:.4f}.\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Métricas de Desempenho do Modelo\n",
    "Com as funções acima, você vai importar os três modelos de aprendizagem supervisionada de sua escolha e executar a função `train_prediction` para cada um deles. Lembre-se de que você vai precisar treinar e usar cada classificador para três diferentes tamanhos de conjuntos de treinamentos: 100, 200 e 300 pontos. Então você deve ter 9 saídas diferentes abaixo – 3 para cada modelo utilizando cada tamanho de conjunto de treinamento. Na célula de código a seguir, você deve implementar o seguinte:\n",
    "- Importe os três modelos de aprendizagem supervisionada que você escolheu na seção anterior.\n",
    "- Inicialize os três modelos e armazene eles em `clf_A`, `clf_B` e `clf_C`.\n",
    " - Defina um `random_state` para cada modelo, se a opção existir.\n",
    " - **Nota:** Utilize as configurações padrão para cada modelo – você vai calibrar um modelo específico em uma seção posterior.\n",
    "- Crie diferentes tamanhos de conjuntos de treinamento para treinar cada modelo.\n",
    " - *Não embaralhe e distribua novamente os dados! Os novos pontos de treinamento devem ser tirados de `X_train` e `y_train`.*\n",
    "- Treine cada modelo com cada tamanho de conjunto de treinamento e faça estimativas com o conjunto de teste (9 vezes no total).  \n",
    "**Nota:** Três tabelas são fornecidas depois da célula de código a seguir, nas quais você deve anotar seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_configuration(data, limit=0):\n",
    "    return data[:][:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- For Naive Bayes:\n",
      "-- With 300\n",
      "Treinando um GaussianNB com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0050 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8038.\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7634.\n",
      "-- With 200\n",
      "Treinando um GaussianNB com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0040 segundos\n",
      "As previsões foram feitas em 0.0010 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8406.\n",
      "As previsões foram feitas em 0.0010 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7244.\n",
      "-- With 100\n",
      "Treinando um GaussianNB com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0050 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8467.\n",
      "As previsões foram feitas em 0.0010 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8029.\n",
      "--\n",
      "\n",
      "\n",
      "- For Gradient Boosting:\n",
      "-- With 300\n",
      "Treinando um GradientBoostingClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.1530 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9739.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7794.\n",
      "-- With 200\n",
      "Treinando um GradientBoostingClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.1120 segundos\n",
      "As previsões foram feitas em 0.0160 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9964.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7591.\n",
      "-- With 100\n",
      "Treinando um GradientBoostingClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0950 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7519.\n",
      "--\n",
      "\n",
      "\n",
      "- For Decision Tree:\n",
      "-- With 300\n",
      "Treinando um DecisionTreeClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0070 segundos\n",
      "As previsões foram feitas em 0.0010 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0010 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.6613.\n",
      "-- With 200\n",
      "Treinando um DecisionTreeClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0070 segundos\n",
      "As previsões foram feitas em 0.0030 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0020 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7500.\n",
      "-- With 100\n",
      "Treinando um DecisionTreeClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0040 segundos\n",
      "As previsões foram feitas em 0.0020 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0010 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.6552.\n",
      "--\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe os três modelos de aprendizagem supervisionada do sklearn\n",
    "# from sklearn import model_A\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn import model_B\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from skearln import model_C\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# TODO: Inicialize os três modelos\n",
    "clf_A = GradientBoostingClassifier(random_state=42)\n",
    "clf_B = DecisionTreeClassifier(random_state=42)\n",
    "clf_C = GaussianNB()\n",
    "\n",
    "classifiers = {\n",
    "    'Gradient Boosting': clf_A,\n",
    "    'Decision Tree': clf_B,\n",
    "    'Naive Bayes': clf_C,\n",
    "}\n",
    "\n",
    "# TODO: Configure os tamanho dos conjuntos de treinamento\n",
    "X_train_100 = size_configuration(X_train, limit=100)\n",
    "y_train_100 = size_configuration(y_train, limit=100)\n",
    "\n",
    "X_train_200 = size_configuration(X_train, limit=200)\n",
    "y_train_200 = size_configuration(y_train, limit=200)\n",
    "\n",
    "X_train_300 = size_configuration(X_train, limit=300)\n",
    "y_train_300 = size_configuration(y_train, limit=300)\n",
    "\n",
    "train_data = {\n",
    "    '100': {\n",
    "        'X': X_train_100,\n",
    "        'y': y_train_100\n",
    "    },\n",
    "    '200': {\n",
    "        'X': X_train_200,\n",
    "        'y': y_train_200\n",
    "    },\n",
    "    '300': {\n",
    "        'X': X_train_300,\n",
    "        'y': y_train_300\n",
    "    }\n",
    "}\n",
    "\n",
    "# TODO: Executar a função 'train_predict' para cada classificador e cada tamanho de conjunto de treinamento\n",
    "for cl_name, cl in classifiers.items():\n",
    "    print \"- For {}:\".format(cl_name)\n",
    "    for (key, value) in train_data.items():\n",
    "        print \"-- With {}\".format(key)\n",
    "        train_predict(cl, value['X'], value['y'], X_test, y_test)\n",
    "    print \"--\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados em tabelas\n",
    "Edite a célula abaixo e veja como a tabela pode ser desenhada em [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables). Você deve salvar seus resultados abaixo nas tabelas fornecidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classificador 1 - GradientBoostingClassifier **  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |       0.0950         |         0.0000              |         1.0000             |      0.7519                |\n",
    "| 200                                |       0.1190         |         0.0000              |         0.9964             |         0.7591                |\n",
    "| 300                                |       0.1300         |         0.0000              |         0.9739             |        0.7794       |\n",
    "\n",
    "** Classificador 2 - DecisionTreeClassifier **  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |       0.0020         |          0.0000             |         1.0000             |         0.6552             |\n",
    "| 200                                |       0.0050         |          0.0020             |         1.0000             |         0.7500             |\n",
    "| 300                                |       0.0170         |          0.0000             |         1.0000             |        0.6613       |\n",
    "\n",
    "** Classificador 3 - GaussianNB **  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |        0.0020        |          0.0020             |          0.8467            |         0.8029        |\n",
    "| 200                                |        0.0050        |          0.0000             |          0.8406            |         0.7244        |\n",
    "| 300                                |        0.0050        |          0.0010             |          0.8038            |         0.7634        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o Melhor Modelo\n",
    "Nesta seção final, você irá escolher dos três modelos de aprendizagem supervisionada o *melhor* para utilizar os dados dos estudantes. Você então executará um busca em matriz otimizada para o modelo em todo o conjunto de treinamento (`X_train` e `y_train`) ao calibrar pelo menos um parâmetro, melhorando em comparação a pontuação F<sub>1</sub> do modelo não calibrado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o Melhor Modelo\n",
    "*Baseando-se nos experimentos que você executou até agora, explique em um ou dois parágrafos ao conselho de supervisores qual modelo que você escolheu como o melhor. Qual modelo é o mais apropriado baseado nos dados disponíveis, recursos limitados, custo e desempenho?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **O modelo que escolhi foi o Gradient Boosting. Como os(as) senhores(as) estão investindo em tecnologia e inovação ao contratar um Engenheiro de Machine Learning para o desenvolvimento de um modelo de classificação, vejo que seu interesse é uma solução ótima hoje e a longo prazo. Com isso em mente, o Gradient Boosting é o modelo ideal para os(as) senhores(as), dado que, mesmo que ele possua um tempo mais longo de treinamento hoje, no futuro e com mais dados ele obterá resultados muito bons e permitirá melhores tomadas de decisão para com o desempenho dos alunos. Além do mais, o tempo necessário para predição é praticamente nulo e esse será o tempo mais considerável com o modelo em produção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 – O Modelo para um Leigo\n",
    "*Em um ou dois parágrafos, explique para o conselho de supervisores, utilizando termos leigos, como o modelo final escolhido deve trabalhar. Tenha certeza que você esteja descrevendo as melhores qualidades do modelo, por exemplo, como o modelo é treinado e como ele faz uma estimativa. Evite jargões técnicos ou matemáticos, como descrever equações ou discutir a implementação do algoritmo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **O Gradient Boosting é um modelo bastante simples de entender. Ele basicamente tenta encontrar quais são as perguntas mais difíceis que ele pode fazer sobre os dados, e foca nessas. Por exemplo: Se temos que estudar para uma prova, e ficamos estudando apenas as coisas fáceis que já sabemos, não vamos ir tão bem nas coisas mais difíceis que não estudamos. Agora, se focarmos em estudar as coisas mais difíceis, há uma boa chance que vamos ir melhor na prova. No nosso caso, é simples imaginar que pessoas com mais faltas tem mais chance de reprovar, porém o ideal é que o foco seja analizar as coisas que não são tão claras, como qual a relação de reprovação com a profissão dos pais. Seguindo essa lógica, a combinação de todas as perguntas mais difíceis sobre os dados gera um modelo que performa bem no geral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Calibrando o Modelo (_Tuning_)\n",
    "Calibre o modelo escolhido. Utilize busca em matriz (`GridSearchCV`) com, pelo menos, um parâmetro importante calibrado com, pelo menos, 3 valores diferentes. Você vai precisar utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você deve implementar o seguinte:\n",
    "- Importe [`sklearn.grid_search.gridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Crie o dicionário de parâmetros que você deseja calibrar para o modelo escolhido.\n",
    " - Examplo: `parameters = {'parameter' : [list of values]}`.\n",
    "- Inicialize o classificador que você escolheu e armazene-o em `clf`.\n",
    "- Crie a função de pontuação F<sub>1</sub> utilizando `make_scorer` e armazene-o em `f1_scorer`.\n",
    " - Estabeleça o parâmetro `pos_label` para o valor correto!\n",
    "- Execute uma busca em matriz no classificador `clf` utilizando o `f1_scorer` como método de pontuação e armazene-o em `grid_obj`.\n",
    "- Treine o objeto de busca em matriz com os dados de treinamento (`X_train`, `y_train`) e armazene-o em `grid_obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8204162057033164 {'n_estimators': 1000, 'loss': 'deviance', 'learning_rate': 0.001, 'max_depth': 1}\n"
     ]
    }
   ],
   "source": [
    "## Gradient Boosting Tuning\n",
    "\n",
    "# TODO: Importe 'GridSearchCV' e 'make_scorer'\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "# TODO: Crie a lista de parâmetros que você gostaria de calibrar\n",
    "parameters = {\n",
    "    'loss': ('deviance', 'exponential'),\n",
    "    'learning_rate': [.001, .01, .1, 1],\n",
    "    'n_estimators': [1, 10, 100, 1000],\n",
    "    'max_depth': [1, 2, 3, 5, 8]\n",
    "}\n",
    "\n",
    "# TODO: Inicialize o classificador\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# TODO: Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "f1_scorer = make_scorer(fbeta_score, beta=1, pos_label='yes')\n",
    "\n",
    "# TODO: Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "grid_obj = GridSearchCV(clf, param_grid=parameters, scoring=f1_scorer)\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "print grid_obj.best_score_, grid_obj.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As previsões foram feitas em 0.0000 segundos.\n",
      "O modelo calibrado tem F1 de 0.8299 no conjunto de treinamento.\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      "O modelo calibrado tem F1 de 0.8000 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Reporte a pontuação final F1 para treinamento e teste depois de calibrar os parâmetrosprint \"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de treinamento.\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de teste.\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Bayes Tuning\n",
    "\n",
    "# TODO: Importe 'GridSearchCV' e 'make_scorer'\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "# TODO: Crie a lista de parâmetros que você gostaria de calibrar\n",
    "parameters = {\n",
    "    'loss': ('deviance', 'exponential'),\n",
    "    'learning_rate': [.001, .01, .1, 1],\n",
    "    'n_estimators': [1, 10, 100, 1000],\n",
    "    'max_depth': [1, 2, 3, 5, 8]\n",
    "}\n",
    "\n",
    "# TODO: Inicialize o classificador\n",
    "clf = GaussianNB()\n",
    "\n",
    "# TODO: Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "f1_scorer = make_scorer(fbeta_score, beta=1, pos_label='yes')\n",
    "\n",
    "# TODO: Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "grid_obj = GridSearchCV(clf, param_grid=parameters, scoring=f1_scorer)\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "print grid_obj.best_score_, grid_obj.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Pontuação F<sub>1</sub> Final\n",
    "*Qual é a pontuação F<sub>1</sub> do modelo final para treinamento e teste? Como ele se compara ao modelo que não foi calibrado?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **A pontuação F<sub>1</sub> final foi de 80%! Houve uma melhora de pouco mais de 2% quando comparado ao modelo não calibrado. É interessante ver os best_params, que mostram que:\n",
    "* n_estimators: Para esse Dataset, é preferível um valor mais alto que o padrão 100.\n",
    "* learning_rate: O melhor valor foi 1/1000, bem menor que o padrão 1/10.\n",
    "* max_depth: Uma profundidade menor teve mais sucesso que uma profundidade maior. O padrão era 3 e o melhor encontrado foi 1.\n",
    "* loss: A função de loss não teve alteração do valor padrão, sendo deviance (que se refere a funcção logística) o melhor.\n",
    "<br><br>\n",
    "    Uma coisa interessante que vi lendo a documentação do SCKit-Learn foi que eles recomendam calibrar o parâmetro `max_depth` pois é uma boa oportunidade para 'tuning'. Citando a documentação \"*Calibre esse valor para melhor performance. O melhor valor depende da interação das variáveis de entrada*\". Ou seja, ao que parece nossos parâmetros não possuem tanta interação entre si, pois uma profundidade de 1 foi a resposta mais acurada para esse parâmetro. Enquanto mais profundidade indicaria maior interação entre as variáveis de entrada. Portanto, pode-se dizer que um *insight* interessante é que não há tanta relação entre quaisquer variáveis do Dataset. Sabendo disso um modelo de Inferência Bayesiana poderia ter sido também uma boa opção, já que este não leva em consideração a relação das variáveis de entrada. Mas ainda creio que Boosting é uma boa escolha, afinal, com cada vez mais escolas querendo melhorar o ensino à seus alunos, haverá mais investimento e um modelo um pouco mais robusto tenderá a mostrar melhores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você completou todas as implementações de código e respondeu todas as questões acima com êxito, você pode finalizar seu trabalho exportando o iPython Nothebook como um document HTML. Você pode fazer isso utilizando o menu acima e navegando para  \n",
    "**File -> Download as -> HTML (.html)**. Inclua a documentação final junto com o notebook para o envio do seu projeto."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
